{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":false},"cell_type":"code","source":"'''\n\n    Standard Modules\n\n'''\nimport time\nimport os\nimport sys\nimport copy\nimport pickle as pkl\nimport collections\nfrom functools import reduce\nfrom functools import partial \n\n\n''' \n\n    External Modules\n\n'''\n\nimport cv2\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm, trange\n\n''' \n\n    PyTorch Modules\n\n'''\n\nimport torch\nfrom torch.utils.data import Dataset\nfrom sklearn.metrics import precision_score,recall_score,f1_score \n\n\nclass Specimen_Dataset(Dataset):\n    \n    def __init__(self, dataset, set_value, transform):\n        self.metadata = dataset\n        self.set_value = set_value\n        self.transform = transform\n        \n    def __len__(self):\n        return self.metadata.shape[0]\n    \n    def __getitem__(self, idx):\n        \n        category_id = -1\n        img = cv2.imread(self.metadata.loc[idx, 'file_name'])\n        img_id = self.metadata.loc[idx, 'id']\n        \n        if self.set_value != 'test_submission':\n            category_id = self.metadata.loc[idx, 'category_id_le_preprocessed']\n        \n        sample = {\n            'img' : img,\n            'category_id' : category_id,\n            'id' : img_id\n        }\n        \n            \n        if self.transform:\n            return self.transform(sample)\n        \n        return sample\n    \n    \nclass Data_Pipeline:\n    \n    def __init__(self, *args):\n        self.content_pipeline = list(args)\n    \n    \n    def __call__(self, obj):\n        \n        return reduce(lambda x,y : y(x), [obj] + self.content_pipeline)\n    \n\nclass Resizer:\n    \n    def __init__(self, output_size):\n        self.output_size = output_size\n        \n    def __call__(self, sample):\n        \n        image = sample['img']\n        image = cv2.resize(src=image, dsize=self.output_size)\n        \n        sample['img'] = image\n        return sample\n    \n    \nclass Normalizer:\n    \n    def __init__(self, mean, std):\n        self.std = std\n        self.mean = mean\n        \n    def __call__(self, sample):\n        \n        img = sample['img']\n        img = (img - self.mean) / self.std\n        \n        sample['img'] = img\n        \n        return sample\n    \nclass ToTensor:\n    \n    def __call__(self, sample):\n        \n        img, category_id = sample['img'], sample['category_id']\n        \n        img = torch.Tensor(img.transpose((2, 0, 1)))\n        category_id = category_id\n        \n        sample['img'] = img\n        sample['category_id'] = category_id\n        \n        return sample\n    \n\nclass NN_Model_Trainer:\n    \n    def __init__(self, model, optimizer, scheduler, label_encoder, loss_func, loaders, **parametres):\n        self.model = model\n        self.optimizer = optimizer\n        self.loss_func = loss_func\n        self.scheduler = scheduler\n        self.loaders = loaders\n        self.label_encoder = label_encoder\n        \n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \n        self.statistics_df = pd.DataFrame(columns=['epoch', \n                                                   'precision', \n                                                   'recall', \n                                                   'f1_score',\n                                                   'learning_rate', \n                                                   'loss', \n                                                   'case'])\n        \n        self.model_train_parametres = parametres['model_param']\n        self.environment_parametres = parametres['environment_param']\n        self.model_directory = self.init_home_directory()\n        self.time_init = time.ctime().replace(' ', '_')\n        self.filelogs_info = self.init_file_logs()\n        \n        \n    def init_home_directory(self):\n        model_directory = os.path.join(self.environment_parametres['abs_path'], \n                                       self.environment_parametres['title'], \n                                       self.environment_parametres['version']\n        )\n\n        if os.path.exists(model_directory): pass    \n        else: os.makedirs(name = model_directory, exist_ok = True)\n\n        return model_directory\n    \n    def init_file_logs(self,):\n    \n        filelogs_path = os.path.join(self.model_directory,\n                                     self.environment_parametres['title'] + '_model_logs_' + self.time_init + '.txt')\n        filelogs_file = open(filelogs_path, 'w') if self.environment_parametres['verbose_mode'] != sys.stdout \\\n                                                 else self.environment_parametres['verbose_mode']\n        \n        return (filelogs_file, filelogs_path)\n    \n    def get_results(self, y_true, y_pred):\n        result_med = collections.namedtuple(\n                                    'result_med', \n                                            [\n                                                'precision', \n                                                'recall', \n                                                'f1_score'\n                                            ]\n        )\n        \n        y_true_cpu, y_pred_cpu = y_true.cpu().numpy(), y_pred.cpu().numpy()\n        \n        result_med.precision = precision_score(y_true_cpu, y_pred_cpu, average='macro')\n        result_med.recall = recall_score(y_true_cpu, y_pred_cpu, average='macro')\n        result_med.f1_score = f1_score(y_true_cpu, y_pred_cpu, average='macro')\n        \n        \n        return result_med\n    \n    \n    def result_wrapper(self, **kwags):\n        \n        results = {\n            'epoch' : kwags['epoch'],\n            'precision' : kwags['precision'],\n            'recall' : kwags['epoch'],\n            'f1_score' : kwags['f1_score'],\n            'learning_rate' : kwags['learning_rate'],\n            'loss' : kwags['loss'],\n            'case' : kwags['case']\n        }\n        \n        return results\n    \n    def parse_batch(self, batch, case):\n        \n        category_existance = 'category_id' if case != 'submission' else 'id'\n        \n        images, categories = batch['img'], batch[category_existance]\n        \n        if self.device == 'cpu':\n            pass\n        \n        else:\n            images, categories = images.to(self.device), \\\n                                 categories.to(self.device)\n            \n        return images, categories\n    \n    \n    def test_model(self, loader_key, case):\n        \n        y_true, y_pred = torch.IntTensor().to(self.device), \\\n                         torch.IntTensor().to(self.device)\n        \n        self.model.eval()\n        with torch.no_grad():\n            for batch_index, batch in enumerate(self.loaders[loader_key], 1):\n                \n                images, categories = self.parse_batch(batch, case)\n                \n                outputs = self.model(images)\n                _, preds = torch.max(outputs, 1)\n                \n                y_true = torch.cat((y_true, categories))\n                y_pred = torch.cat((y_pred, preds))\n                \n#                 break\n                \n        results = self.get_results(y_true, y_pred)\n        \n        \n        return results\n    \n    def train_model(self):\n        \n        def init_model_state_info():\n            model_state_info = {\n                    'model_state_dict' : None,\n                    'optimizer_state_dict' : None,\n                    'best_model' : {\n                        'f1_score' : -10,\n                        'model_state_dict' : None,\n                        'optimizer_state_dict' : None\n                    },\n                    'img_size' : self.model_train_parametres['img_size'],\n                    'epochs' : self.model_train_parametres['epochs'],\n                    'epochs_left' : self.model_train_parametres['epochs'],\n                    'learnin_rate' : self.model_train_parametres['learning_rate'],\n                    'loss' : None,\n                    'f1_score' : None,\n                    'model_logs' : dict((zip(range(self.model_train_parametres['epochs']), \n                                             [None] * self.model_train_parametres['epochs'])))\n            }\n\n            return model_state_info\n        \n        \n        self.model = self.model.to(self.device)\n        model_state_info = init_model_state_info()\n        \n        \n        if self.model_train_parametres['Retrain_path']:\n            \n            model_state_info = torch.load(self.model_train_parametres['Retrain_path'])\n            self.model.load_state_dict(model_state_info['model_state_dict'])\n            \n            self.optimizer = self.optimizer(self.model.parameters(), \n                                            lr=self.model_train_parametres['learning_rate'], \n                                            momentum=self.model_train_parametres['momentum'])\n            \n            self.optimizer.load_state_dict(model_state_info['optimizer_state_dict'])\n            \n            self.scheduler = self.scheduler(self.optimizer, step_size=7, gamma=0.1)\n            \n            print(model_state_info['best_model']['f1_score'])\n            \n#             self.get_submission()\n#             return\n            \n            \n            \n        else:\n            self.optimizer = self.optimizer(self.model.parameters(), \n                                            lr=self.model_train_parametres['learning_rate'], \n                                            momentum=self.model_train_parametres['momentum'])\n            \n            self.scheduler = self.scheduler(self.optimizer, step_size=7, gamma=0.1)\n            \n            \n        parametrs_string = 'learning_rate : {}, momentum : {}, epochs : {}, img_size : {}'.format(self.model_train_parametres['learning_rate'],\n                                                                                                  self.model_train_parametres['momentum'],\n                                                                                                  self.model_train_parametres['epochs'],\n                                                                                                  self.model_train_parametres['img_size'],)\n\n        cli_string = \"optimizer : {}, loss_function : {}, num_labels : {}\".format(\n            self.model_train_parametres['optimizer'],\n            self.model_train_parametres['loss_function'],\n            self.model_train_parametres['num_of_classes']\n        )\n\n        print('CLI PARAMETRES : ', file = self.filelogs_info[0])\n        print(cli_string, file = self.filelogs_info[0])\n        print('HYPERPARAMETRS : ', file = self.filelogs_info[0])\n        print(parametrs_string, file = self.filelogs_info[0])\n        print('DEVICE : ',self.device, file = self.filelogs_info[0])\n\n                \n        filelogs_fmt = '{} -> Epoch {} -> Batch_index {} -> {} -> {}'\n        epoch_logs_format = '{} -> Epoch_loss : {}'\n        \n        \n        for epoch in trange(1, model_state_info['epochs_left'] + 1, desc = 'epochs'):\n        \n            epoch_loss = 0.0\n            \n            y_true, y_pred = torch.IntTensor().to(self.device), \\\n                             torch.IntTensor().to(self.device)\n            \n            self.model.train()\n            \n            for batch_index, batch in enumerate(tqdm(self.loaders['train'], leave=False), 1):\n                \n                images, categories = self.parse_batch(batch, case='train')\n                \n                self.optimizer.zero_grad()\n                \n                outputs = self.model(images)\n                _, preds = torch.max(outputs, 1)\n                \n                y_pred = torch.cat((y_pred, preds))\n                y_true = torch.cat((y_true, categories))\n                \n                loss = self.loss_func(outputs, categories)\n                epoch_loss += loss.item() * images.size(0)\n                \n                loss.backward()\n                self.optimizer.step()\n                \n                print(filelogs_fmt.format(time.ctime() ,epoch, batch_index,'loss', loss.item()), file = self.filelogs_info[0])\n                \n#                 if batch_index == 10:\n#                     break\n            \n\n            epoch_loss = epoch_loss / (batch_index * self.model_train_parametres['batch_size'])\n            \n            res_train = self.get_results(y_true, y_pred)\n            res_val = self.test_model('val', case='val')\n            \n            self.scheduler.step()\n            \n            if res_val.f1_score > model_state_info['best_model']['f1_score']:\n                model_state_info['best_model']['f1_score'] = res_val.f1_score\n                model_state_info['best_model']['model_state_dict'] = copy.deepcopy(self.model.state_dict())\n                model_state_info['best_model']['optimizer_state_dict'] = copy.deepcopy(self.optimizer.state_dict())\n                \n                \n                \n            \n            self.statistics_df = self.statistics_df.append(self.result_wrapper(\n                                                            epoch=epoch,\n                                                            precision=res_train.precision,\n                                                            recall=res_train.recall,\n                                                            f1_score=res_train.f1_score,\n                                                            learning_rate=self.optimizer.param_groups[0]['lr'],\n                                                            loss=epoch_loss,\n                                                            case='train',\n                            ),\n                                                      ignore_index=True)\n            \n            self.statistics_df = self.statistics_df.append(self.result_wrapper(\n                                                            epoch=epoch,\n                                                            precision=res_val.precision,\n                                                            recall=res_val.recall,\n                                                            f1_score=res_val.f1_score,\n                                                            learning_rate=self.optimizer.param_groups[0]['lr'],\n                                                            loss=epoch_loss,\n                                                            case='val',\n                            ),\n                                                      ignore_index=True)\n            \n            print(filelogs_fmt.format(time.ctime() ,epoch, batch_index,'loss', epoch_loss), file = self.filelogs_info[0])\n            \n            model_state_info['model_logs'][epoch] = res_val.f1_score\n            \n            model_state_info['model_state_dict'] = self.model.state_dict()\n            model_state_info['optimizer_state_dict'] = self.optimizer.state_dict()\n            model_state_info['epochs_left'] = model_state_info['epochs'] - epoch\n            model_state_info['learning_rate'] = self.optimizer.param_groups[0]['lr']\n            \n            \n            torch.save(model_state_info, os.path.join(self.model_directory,self.environment_parametres['title'] + '_model_state_info.pth'))\n            self.statistics_df.to_csv(os.path.join(self.model_directory,self.environment_parametres['title'] + '_statistics.csv'))\n#             break\n    \n        self.model.load_state_dict(model_state_info['best_model']['model_state_dict'])\n        res_test = self.test_model('test', 'test')\n        self.statistics_df = self.statistics_df.append(self.result_wrapper(\n                                                        epoch=epoch,\n                                                        precision=res_test.precision,\n                                                        recall=res_test.recall,\n                                                        f1_score=res_test.f1_score,\n                                                        learning_rate=self.optimizer.param_groups[0]['lr'],\n                                                        loss=epoch_loss,\n                                                        case='test',\n                        ),\n                                                  ignore_index=True)\n    \n        self.get_submission()\n    \n    \n    def get_submission(self):\n        \n        self.model.eval()\n        \n        y_pred, all_ids = torch.IntTensor().to(self.device), \\\n                          torch.IntTensor().to(self.device)\n        \n        with torch.no_grad():\n            for batch_index, batch in enumerate(tqdm(self.loaders['submission']), 1):\n                images, ids = self.parse_batch(batch, 'submission')\n                \n                outputs = self.model(images)\n                _, preds = torch.max(outputs, 1)\n                \n                y_pred = torch.cat((y_pred, preds))\n                all_ids = torch.cat((all_ids, ids))\n                \n#                 break\n        \n        y_pred_deprocessed = self.label_encoder.inverse_transform(y_pred.cpu().numpy().astype(int))\n        submission_df = pd.DataFrame({'Id' : all_ids.cpu().numpy().astype(int), 'Predicted' : y_pred_deprocessed})\n        \n        \n        self.statistics_df.to_csv(os.path.join(self.model_directory,self.environment_parametres['title'] + '_statistics.csv'))\n        submission_df.to_csv(os.path.join(self.model_directory,self.environment_parametres['title'] + 'submission_df.csv'), index=False)\n\n\n            \n                \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n    \n\n        ","execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}