{"cells":[{"metadata":{"_uuid":"0aa551ec-8cd7-4c07-bd7c-91fb3c7a0230","_cell_guid":"bc50f066-5ea3-48ad-9541-48c4f2f70281","trusted":true},"cell_type":"markdown","source":"# Import Modules"},{"metadata":{"_uuid":"5a216926-9776-493a-854c-7350dbbbf89a","_cell_guid":"25a19172-3c92-4ff9-ae0e-be7cdebc89f6","trusted":true},"cell_type":"markdown","source":"## Standard modules"},{"metadata":{"_uuid":"92f1ca38-3165-4db8-a93b-03fad539faf5","_cell_guid":"849b787a-3353-4858-b779-7e40895cf838","trusted":true},"cell_type":"code","source":"import os\nimport json\nimport pickle as pkl\n\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02fdaf91-88f2-495b-bf8a-bcd94d3544ab","_cell_guid":"8b8e722a-a07a-4cc4-9b6a-526c08babeb2","trusted":true},"cell_type":"markdown","source":"## External modules"},{"metadata":{"_uuid":"77056eb9-d1a9-407f-b804-d02edce49f93","_cell_guid":"ce93a315-094f-4f63-9d78-fdb97b6cb0ba","trusted":true},"cell_type":"code","source":"import warnings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import precision_score, \\\n                            recall_score, \\\n                            f1_score, \\\n                            roc_auc_score \\\n            \nfrom tqdm import tqdm, trange\nfrom pylab import rcParams\n\n\n\ntqdm.pandas()\n%matplotlib inline\nwarnings.filterwarnings('ignore')\nrcParams['figure.figsize'] = 10, 10","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d0436b0-7553-4949-97e7-71e05a5fe61e","_cell_guid":"78d393cd-1d05-431c-95ca-090540273e84","trusted":true},"cell_type":"markdown","source":"## Internal modules"},{"metadata":{"_uuid":"b85898a8-eb83-4af2-b2f5-b8936690ba64","_cell_guid":"05c4280e-a667-427b-9376-2e2c275f52c2","trusted":true},"cell_type":"code","source":"import utils_scripts as utlis","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1966ae51-88cf-404c-a50f-1fd26462ce4d","_cell_guid":"71ed160e-8270-4b9e-9b09-ca8be2dc2f43","trusted":true},"cell_type":"markdown","source":"# Constants"},{"metadata":{"_uuid":"290a79bb-ed10-45c0-9745-1e811ff7c737","_cell_guid":"f6f49477-36bf-4f31-9dd4-fc885012d966","trusted":true},"cell_type":"code","source":"RANDOM_SEED = 17\nnp.random.seed(RANDOM_SEED)\n\nABS_PATH = '/kaggle/input/herbarium-2020-fgvc7/nybg2020/'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"adb19da7-e3d5-4dd8-9e9a-d11d46091be3","_cell_guid":"34405e7a-e525-4b43-8caf-4af5ea94df7e","trusted":true},"cell_type":"markdown","source":"# Data EDA"},{"metadata":{"_uuid":"a8b7d972-bc00-49d7-8e8a-5a2a1f9efd6d","_cell_guid":"11ff565c-a917-489e-9eaf-8b2462de610a","trusted":true},"cell_type":"code","source":"def get_result_df(path, set_value):\n    with open(os.path.join(ABS_PATH, set_value, 'metadata.json'), \"r\", encoding=\"ISO-8859-1\") as file:\n        metadata = json.load(file)\n        \n    img_info = pd.DataFrame(metadata['images'])\n    \n    if set_value == 'train':\n        annotation_info = pd.DataFrame(metadata['annotations']).drop(columns=['image_id'])\n        img_info = img_info.merge(annotation_info, on='id')\n    \n    img_info['file_name'] = img_info['file_name'].progress_apply(lambda x : os.path.join(path, set_value, x))\n    return img_info","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c9cda8a-02aa-43e2-847a-eda8b78e094e","_cell_guid":"15750eb0-5db4-4cf8-9eb2-48bc812dbc44","trusted":true},"cell_type":"code","source":"metadata_train = get_result_df(path=ABS_PATH, set_value='train')\nmetadata_test = get_result_df(path=ABS_PATH, set_value='test')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7920dbf-df26-4de8-b4c4-dc27e0f19d52","_cell_guid":"e4de0f09-6669-4a73-9cf9-90e7e8e7ac6c","trusted":true},"cell_type":"code","source":"classes = sorted(list(metadata_train['category_id'].unique()))\nclasses == list(range(min(classes), len(classes) + 1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8a792df-86ef-4795-9a5c-4683c55047fe","_cell_guid":"0ddc2027-6c83-40fe-a103-be457a350011","trusted":true},"cell_type":"code","source":"metadata_train['category_id'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74e73d46-a6c3-4022-96b9-e7ac26adaa80","_cell_guid":"2e4ecc3c-93e6-44cb-81c6-a111efca3ead","trusted":true},"cell_type":"markdown","source":"## Label preprocessing"},{"metadata":{"_uuid":"e53fe304-421b-4447-af94-d7cbd87b0a10","_cell_guid":"8744a411-e669-4126-8d5c-c682876c1b5f","trusted":true},"cell_type":"code","source":"# le_preprocessor = LabelEncoder()\n# le_preprocessor.fit(metadata_train['category_id'])\n# metadata_train['category_id_le_preprocessed'] = le_preprocessor.transform(metadata_train['category_id'])\n\n# classes = sorted(list(metadata_train['category_id_le_preprocessed'].unique()))\n# classes == list(range(min(classes), len(classes)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fef5a5a8-6019-4af6-b823-1094b09a5bf0","_cell_guid":"fe1c2e03-b293-4948-88df-fa3e6d6ca0f6","trusted":true},"cell_type":"markdown","source":"# Train Test Split"},{"metadata":{"_uuid":"a229770a-7627-4236-a7ae-bdf1d2c3823c","_cell_guid":"0a25cb7a-23b6-4010-b92a-be1677f79f69","trusted":true},"cell_type":"code","source":"# train_indices, test_indices, _, _ = train_test_split(metadata_train.index, \n#                                                      metadata_train['category_id_le_preprocessed'],\n#                                                      train_size=0.75, \n#                                                      random_state=RANDOM_SEED,                                                     \n#                                                      shuffle=True, \n#                                                      stratify=metadata_train['category_id_le_preprocessed'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee02e70c-2841-48f0-8876-ad4408c5d4b4","_cell_guid":"a6a3dfe8-3b3e-4527-b1f8-85fad2163d5d","trusted":true},"cell_type":"code","source":"min_samples = 3\ngrouped = metadata_train.groupby('category_id', as_index=False).count()\nlittle_classes = grouped[grouped['id'] < min_samples]['category_id']\nprint(metadata_train.shape)\n\nbig_classes_cond = metadata_train['category_id'].isin(little_classes.values)\nmetadata_train = metadata_train[big_classes_cond == False].reset_index().drop(columns=['index'])\nprint(metadata_train.shape)\n\n\nle_preprocessor = LabelEncoder()\nle_preprocessor.fit(metadata_train['category_id'])\nmetadata_train['category_id_le_preprocessed'] = le_preprocessor.transform(metadata_train['category_id'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5d7f6e5-ec1b-4067-9e04-3f14bccd6c31","_cell_guid":"2b03f035-6cf3-4332-9b73-2cb8a4ef41f8","trusted":true},"cell_type":"code","source":"train_indices, test_indices, _, _ = train_test_split(metadata_train.index, \n                                                     metadata_train['category_id_le_preprocessed'],\n                                                     train_size=0.75, \n                                                     random_state=RANDOM_SEED,                                                     \n                                                     shuffle=True)\n\ntrain_data = metadata_train.loc[train_indices, :]\nprint(train_data.shape)\n\ntrain_data.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c60dc04-a16f-4366-be97-02d65f53d174","_cell_guid":"f12d21b4-3885-4d3b-8284-b0f0753d7f6b","trusted":true},"cell_type":"code","source":"test_data = metadata_train.loc[test_indices, :]\nprint(test_data.shape)\n\ntest_data.reset_index(inplace=True)\n\ntest_indices, val_indices, _, _ = train_test_split(test_data.index, \n                                                   test_data['category_id_le_preprocessed'],\n                                                   train_size=0.80, \n                                                   random_state=RANDOM_SEED,                                                     \n                                                   shuffle=True)\n\nval_data = test_data.loc[val_indices, :]\nprint(val_data.shape)\nval_data.reset_index(inplace=True)\n\ntest_data = test_data.loc[test_indices, :]\nprint(test_data.shape)\ntest_data.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0a408e6-8c29-4180-8220-e020e421e9e5","_cell_guid":"87cb433e-80b6-4327-8558-a1b100f4f9f7","trusted":true},"cell_type":"markdown","source":"## Class weights"},{"metadata":{"_uuid":"10ec29ab-2656-4736-b581-2b598d90ba99","_cell_guid":"57b2c639-0e00-4583-a38b-715db9bb1d67","trusted":true},"cell_type":"code","source":"class_weights = Counter(train_data['category_id_le_preprocessed'])\nclass_weights = [item[1] for item in sorted(list(class_weights.items()), key=lambda x : x[0])]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96f60a67-59c3-4ac1-98a4-795033099f26","_cell_guid":"066ce428-acec-4a45-bc10-39d8eacf3bbc","trusted":true},"cell_type":"markdown","source":"# Model Development"},{"metadata":{"_uuid":"48f73f3e-c3f4-48c7-a28e-cdb330981290","_cell_guid":"9deaf292-5e5d-43bd-bcc6-1f099735297d","trusted":true},"cell_type":"code","source":"import torch","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10d1e521-7a8e-449d-aa70-32b1d028645a","_cell_guid":"01b7e992-2e16-494b-a5df-6c239c496e6a","trusted":true},"cell_type":"code","source":"from torch import Tensor\nfrom torch.utils.data import DataLoader\nfrom utils_scripts import Specimen_Dataset, \\\n                          Data_Pipeline, \\\n                          Resizer, \\\n                          Normalizer, \\\n                          ToTensor \\\n#                           NN_Model_Helper","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c4cd42b-1b7b-49b6-971f-dacb9d403b28","_cell_guid":"5172f2ec-4481-43e6-84a8-fb31caef25d1","trusted":true},"cell_type":"code","source":"data_pipe_obj = Data_Pipeline(\n    Resizer(output_size=(128,128)),\n    Normalizer(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n    ToTensor()\n)\n\ntrain_dataset = Specimen_Dataset(dataset=train_data, set_value='train', transform=data_pipe_obj)\ntest_dataset = Specimen_Dataset(dataset=test_data, set_value='test', transform=data_pipe_obj)\nval_dataset = Specimen_Dataset(dataset=val_data, set_value='val', transform=data_pipe_obj)\ntest_subm_dataset = Specimen_Dataset(dataset=metadata_test, set_value='test_submission', transform=data_pipe_obj)\n\nprint(f'train dataset : {len(train_dataset)}')\nprint(f'test dataset : {len(test_dataset)}')\nprint(f'val dataset : {len(val_dataset)}')\nprint(f'subm dataset : {len(test_subm_dataset)}')\n\nBATCH_SIZE = 128\ntorch.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed(RANDOM_SEED)\n\ntrain_dataloader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=BATCH_SIZE, num_workers = 8, pin_memory=False)\ntest_dataloader = DataLoader(dataset=test_dataset, shuffle=True, batch_size=BATCH_SIZE, num_workers = 8, pin_memory=False)\nval_dataloader = DataLoader(dataset=val_dataset, shuffle=True, batch_size=BATCH_SIZE, num_workers = 8, pin_memory=False)\ntest_subm_dataloader = DataLoader(dataset=test_subm_dataset, shuffle=False, batch_size=BATCH_SIZE, num_workers = 8, pin_memory=False)\n\n\nloaders = {\n    'train' : train_dataloader,\n    'test' : test_dataloader,\n    'val' : val_dataloader,\n    'submission' : test_subm_dataloader\n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"024ef4c6-2900-4144-9731-62deb0ba8681","_cell_guid":"58ddb11f-d7e2-4921-96a7-ff907e94ef3c","trusted":true},"cell_type":"markdown","source":"## ResNet-50"},{"metadata":{"_uuid":"7030bacf-e1f2-4d43-8da7-bf355c71a02a","_cell_guid":"fdc32562-2730-4ec4-b905-a45e4fe038f5","trusted":true},"cell_type":"code","source":"from collections import namedtuple\nfrom torch.optim import SGD, lr_scheduler, Adam\nfrom torch.nn import Linear, CrossEntropyLoss, AdaptiveAvgPool2d\nfrom torchvision.models import resnet50","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74cc1357-1d10-4fa3-afb6-86c1b4839a73","_cell_guid":"683aa6fc-d973-44e1-a415-34b265733349","trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet50_model = resnet50(pretrained=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c831ff64-3762-4b7c-b236-ce8366693ead","_cell_guid":"51c82f71-8167-40dd-9886-3fbe77ce20b5","trusted":true},"cell_type":"code","source":"cross_entropy_loss_function = CrossEntropyLoss()\noptimizer_sgd = Adam\nexp_lr_scheduler = lr_scheduler.ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_OF_CLASSES = metadata_train['category_id_le_preprocessed'].unique().shape[0]\nIMG_SIZE = '128x128'\nBATCH_SIZE = 128\nRANDOM_SEED = 17\nEPOCHS = 12\nMIN_SAMPLES = min_samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'logs' : {\n        'abs_path' : '/kaggle/working/',\n        'version' : 'V1',\n        'title' : 'Resnet-50',\n    },\n    'info' : {\n        'model' : 'Resnet-50',\n        'optimizer' : 'Adam',\n        'scheduler' : 'ReduceLROnPlateau',\n        'loss' : 'Cross_Entropy'\n    },\n    'model_params' : {\n        'is_freeze' : False,\n        'pretrained' : True,\n        'num_of_classes' : NUM_OF_CLASSES,\n    },\n    'optimizer_params' : {\n        'lr' : 4e-4,\n#         'momentum' : 0.9,\n        'amsgrad' : False\n    },\n    'scheduler_params' : {\n        'mode' : 'min',\n        'factor' : 0.75,\n        'patience' : 5,\n        'eps' : 1e-6\n    },\n    'common_params' : {\n        'epochs' : 1,\n        'start' : 1,\n        'img_size' : '256x256',\n        'batch_size' : 256,\n        'random_seed' : RANDOM_SEED,\n        'min_sample' : MIN_SAMPLES,\n        'num_of_workers' : 8\n    }\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_OF_CLASSES","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport copy\n\nfrom timeit import default_timer as timer\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NN_Model_Helper:\n\n    def __init__(self,model, \n                 optimizer, \n                 scheduler, \n                 loss_function,\n                 label_encoder,\n                 loaders:dict, \n                 params:dict):\n\n        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n        self.model = model.to(self.device)\n        self.loss_function = loss_function\n        self.label_encoder = label_encoder\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.loaders = loaders\n        self.params = params\n\n        self.is_best_model = False\n        self.model_state_info = self.init_model_state_info()\n        self.train_logs = pd.DataFrame(columns=['epoch', 'loss', 'learning_rate', 'precision', 'recall', 'f1_score'])\n        self.val_logs = pd.DataFrame(columns=['epoch', 'loss', 'learning_rate', 'precision', 'recall', 'f1_score'])\n        self.results = pd.DataFrame(columns=['phase', 'precision', 'recall', 'f1_score'])\n        self.submission = pd.DataFrame(columns=['Id', 'Predicted'])\n\n        self.filelogs_info = self.init_logs()\n\n        self._weights = None\n        self._num_of_weights = None\n\n        self.total_time = timer()\n        self.epoch_time = None\n        self.kaggle_limit = 32400\n\n    \n    def init_logs(self,):\n        model_directory = self.init_model_directory()\n        \n        return {\n            'train_logs_pd' : os.path.join(model_directory, 'train_logs.csv'),\n            'val_logs_pd' : os.path.join(model_directory, 'val_logs.csv'),\n            'results' : os.path.join(model_directory, 'results.csv'),\n            'submission_df' : os.path.join(model_directory, 'submission.csv'),\n            'txt_logs' : os.path.join(model_directory, 'training_logs.txt'),\n            'model_state_info' : os.path.join(model_directory, 'model_state_info.pth')\n\n        }\n\n    def init_model_directory(self):\n        logs = self.params.get('logs')\n        model_directory = os.path.join(logs.get('abs_path'), logs.get('title'), logs.get('version'))\n        \n        os.makedirs(name = model_directory, exist_ok = True)\n        return model_directory\n\n    def init_model_state_info(self,):\n        model_state_info = {\n            'last_model' : None,\n            'best_model' : None,\n        }\n        return model_state_info\n\n    @property\n    def weights(self):\n        weights = {}\n        for param in self.model.named_parameters():\n            weights[param[0]] = {\n                'size' : param[1].flatten().size()[0],\n                'requires_grad' : param[1].requires_grad\n            }\n\n        self._weights = weights\n        \n        return self._weights\n\n    @property\n    def num_of_weights(self,):\n        num_ = 0\n        for param_name, info in self.weights.items():\n            if info['requires_grad']:\n                num_ += info['size']\n\n        self._num_of_weights = num_\n        return self._num_of_weights\n\n    def load_model(self,model_phase):\n        model = self.model_state_info.get(model_phase)\n        if model.get('model_state_dict') and model.get('optimizer_state_dict'):\n            self.model.load_state_dict(model['model_state_dict'])\n            self.optimizer.load_state_dict(model['optimizer_state_dict'])\n            \n            if self.device != 'cpu':\n                self.model = self.model.to(self.device)\n            \n            if model_phase == 'best_model':\n                self.is_best_model = True\n\n\n            return True\n        \n        return False\n\n    def update_model(self, path):\n        self.model_state_info = torch.load(path, map_location=self.device)\n        self.load_model(model_phase='last_model')\n\n    def assign_model_state_dict(self, model_phase, f1_score, loss):\n        keys = self.get_model_save_snippet()\n        values = [copy.deepcopy(self.model.state_dict()), copy.deepcopy(self.optimizer.state_dict()), \n                 f1_score, loss, self.weights]\n        \n        self.model_state_info[model_phase] = dict(zip(keys,values))\n\n    def pd_logs_update(self, phase,**row):\n        if phase == 'train':\n            self.train_logs = self.train_logs.append(row, ignore_index=True)\n        elif phase == 'val':\n            self.val_logs = self.val_logs.append(row, ignore_index=True)\n    \n    def metrics_calculation(self,y_true, y_pred, average='macro'):\n        y_true_cpu = y_true if not y_true.is_cuda else y_true.to('cpu').numpy()\n        y_pred_cpu = y_pred if not y_pred.is_cuda else y_pred.to('cpu').numpy()\n\n        return {\n            'precision' : precision_score(y_true_cpu,y_pred_cpu,average=average),\n            'recall' : recall_score(y_true_cpu,y_pred_cpu,average=average),\n            'f1_score' : f1_score(y_true_cpu,y_pred_cpu,average=average)\n        }\n\n    def results_update(self,y_true, y_pred, phase, metrics=None):\n        if metrics is None:\n            metrics = self.metrics_calculation(y_true, y_pred)\n        \n        metrics['phase'] = phase\n\n        self.results = self.results.append(metrics, ignore_index=True)\n\n    def metrics_logs_update(self, y_true, y_pred, epoch, loss, learning_rate, phase, metrics=None):\n        if metrics is None:\n            metrics = self.metrics_calculation(y_true, y_pred)\n        \n        metrics['epoch'] = epoch\n        metrics['loss'] = loss\n        metrics['learning_rate'] = learning_rate\n\n        self.pd_logs_update(phase, **metrics)\n\n    def init_model(self,is_freeze=True):\n        num_of_classes = self.params.get('model_params').get('num_of_classes')\n        self.model.fc = Linear(in_features=self.model.fc.in_features, out_features=num_of_classes)\n        \n        if self.device != 'cpu':\n            self.model = self.model.to(self.device)\n\n        optim_params = self.params.get('optimizer_params')\n        self.optimizer = self.optimizer(self.model.parameters(), **optim_params)\n        \n        scheduler_params = self.params.get('scheduler_params')\n        self.scheduler = self.scheduler(self.optimizer, **scheduler_params)\n        \n        if is_freeze:\n            self.freeze()\n\n    def freeze(self, is_fc=True):\n        for param in self.model.named_parameters():\n            if (param[0] == 'fc.weight' or param[0] == 'fc.bias') and is_fc:\n                continue\n\n            else:\n                param[1].requires_grad = False\n\n    def get_model_save_snippet(self):\n        return [\n            'model_state_dict',\n            'optimizer_state_dict',\n            'f1_score',\n            'loss',\n            'weights_info'\n        ]\n\n    def print_params(self, params:dict, outputfile, is_weights=False):\n        param_format = '{:15} : {:15}'\n        for key, value in params.items():\n            print(param_format.format(key, value), file=outputfile)\n        \n        print(file=outputfile)\n        print(100*'*', file=outputfile)\n        print(file=outputfile)\n\n        if is_weights:\n            print(param_format.format('The num of weights : ', self.num_of_weights), file=outputfile)\n            print(file=outputfile)\n            print(100*'*', file=outputfile)\n            print(file=outputfile)\n\n    def parse_batch(self, batch, phase):\n        img = batch.get('img')\n        img_id = batch.get('id')\n        category_id = batch.get('category_id')\n\n        if phase == 'submission' and self.device != 'cpu':\n            return img.to(self.device), img_id.to(self.device)\n        elif phase == 'submission' and self.device == 'cpu':\n            return img, img_id\n        \n        elif phase != 'submission' and self.device != 'cpu':\n            return img.to(self.device), category_id.to(self.device)\n\n        else:\n            return img, category_id\n\n    def make_checkpoint(self):\n        torch.save(self.model_state_info, self.filelogs_info.get('model_state_info'))\n        self.train_logs.to_csv(self.filelogs_info.get('train_logs_pd'))\n        self.val_logs.to_csv(self.filelogs_info.get('val_logs_pd'))\n        self.results.to_csv(self.filelogs_info.get('results'))\n\n    def check_left_time(self, mode='epoch'):\n        ratio = 1 if mode == 'epoch' else 2\n\n        if (self.kaggle_limit - self.total_time) < self.epoch_time // ratio:\n            return False\n        else:\n            return True\n\n    def train(self,model_freeze,update_path,epochs, is_test=False, start=1):\n\n        self.epoch_time = timer()\n        \n        txt_outputfile = open(self.filelogs_info.get('txt_logs'), 'w')\n\n        self.print_params(params=self.params.get('logs'), outputfile=txt_outputfile)\n        self.print_params(params=self.params.get('info'), outputfile=txt_outputfile)\n        self.print_params(params=self.params.get('model_params'), outputfile=txt_outputfile)\n        self.print_params(params=self.params.get('optimizer_params'), outputfile=txt_outputfile)\n        self.print_params(params=self.params.get('scheduler_params'), outputfile=txt_outputfile)\n        self.print_params(params=self.params.get('common_params'), outputfile=txt_outputfile, is_weights=True)\n\n        info = self.params.get('info')\n\n        filelogs_fmt = '{} -> Epoch {} -> Batch_index {} -> Loss {}'\n        epoch_logs_format = '{} -> Epoch_loss : {}'\n        \n        self.init_model(is_freeze=model_freeze)\n\n        if update_path:\n            self.update_model(path=update_path)\n        \n        if model_freeze:\n            self.freeze()\n\n        best_f1_score = -1.0\n        \n        for epoch_index in trange(start, epochs+1, desc='epochs'):\n            \n            epoch_loss = 0.0\n            if self.device == 'cpu':\n                y_true, y_pred = torch.IntTensor([], device=self.device), torch.IntTensor([], device=self.device)\n            \n            else:\n                y_true, y_pred = torch.IntTensor([]).to(self.device), torch.IntTensor([]).to(self.device)\n\n            for batch_index, batch in enumerate(tqdm(self.loaders.get('train')),1):\n                \n                img, category_id = self.parse_batch(batch, phase='train')\n\n                self.optimizer.zero_grad()\n                outputs = self.model(img)\n\n                _, preds = torch.max(outputs, 1)\n\n                y_true = torch.cat((y_true, category_id))\n                y_pred = torch.cat((y_pred, preds))\n\n                loss = self.loss_function(outputs, category_id)\n                loss_item = loss.item()\n                epoch_loss += loss_item\n                \n                loss.backward()\n                self.optimizer.step()\n\n                print(filelogs_fmt.format(time.ctime() ,epoch_index, batch_index, loss_item), file=txt_outputfile)\n\n                if is_test and batch_index == 2:\n                    break\n\n            \n            epoch_loss = epoch_loss / (batch_index)\n            metrics_val, avg_val_loss = self.test(phase='val', epoch=epoch_index,loss=epoch_loss, is_test=is_test)\n            current_f1_score = metrics_val.get('f1_score')\n\n            self.metrics_logs_update(y_true,\n                                     y_pred, \n                                     epoch=epoch_index, \n                                     loss=epoch_loss, \n                                     learning_rate=self.optimizer.param_groups[0]['lr'], \n                                     phase='train')\n\n\n            if info.get('scheduler') is not None and info.get('scheduler') == 'ReduceLROnPlateau':\n                self.scheduler.step(avg_val_loss)\n            \n            else:\n                self.scheduler.step()\n\n            self.assign_model_state_dict(model_phase='last_model', f1_score=current_f1_score, loss=epoch_loss)\n\n            if current_f1_score > best_f1_score:\n                best_f1_score = current_f1_score\n                self.assign_model_state_dict(model_phase='best_model', f1_score=best_f1_score, loss=epoch_loss)\n\n            self.make_checkpoint()\n\n            if is_test:\n                break\n\n            if epoch_index == 1:\n                self.epoch_time = timer() - self.epoch_time\n\n            if not self.check_left_time(mode='epoch'):\n                print('', file=txt_outputfile)\n                print('Kaggle time limit exceeded. Epoch mode', file=txt_outputfile)\n                break\n\n\n        if not self.check_left_time(mode='test'):\n            print('', file=txt_outputfile)\n            print('Kaggle time limit exceeded. Test mode', file=txt_outputfile)\n            return \n        \n        self.results_update(y_true, y_pred, phase='train')\n        self.load_model(model_phase='best_model')\n        self.test(phase='val', epoch=epoch_index, loss=epoch_loss, is_last=True, is_test=is_test)\n        self.test(phase='test', is_test=is_test)\n\n        self.make_checkpoint()\n        self.submit(is_test=is_test)\n\n    def test(self, phase, update_path=None, epoch=None, loss=None, is_last=False, is_test=False):\n\n        if update_path is not None:\n            self.update_model(path=update_path)\n            self.load_model(model_phase='best_model')\n\n        if not self.is_best_model and phase == 'test':\n            self.load_model(model_phase='best_model')\n        \n        elif not self.is_best_model and phase == 'val' and is_last==True:\n            self.load_model(model_phase='best_model')\n        \n        if self.device == 'cpu':\n                y_true, y_pred = torch.IntTensor([], device=self.device), torch.IntTensor([], device=self.device)\n            \n        else:\n            y_true, y_pred = torch.IntTensor([]).to(self.device), torch.IntTensor([]).to(self.device)\n\n        avg_loss = 0.0\n\n        for batch_index, batch in enumerate(tqdm(self.loaders.get(phase)),1):\n            img, category_id = self.parse_batch(batch, phase)\n            \n            with torch.no_grad():\n                outputs = self.model(img)\n\n            _, preds = torch.max(outputs,1)\n            y_true = torch.cat((y_true, category_id))\n            y_pred = torch.cat((y_pred, preds))\n\n            loss = self.loss_function(outputs, category_id)\n            avg_loss += loss.item()\n\n            if is_test and batch_index == 2:\n                break\n        \n        avg_loss = avg_loss // batch_index\n        metrics = self.metrics_calculation(y_true, y_pred)\n\n        if phase == 'val' and not is_last:        \n            self.metrics_logs_update(y_true, \n                                    y_pred, \n                                    epoch, \n                                    loss, \n                                    learning_rate=self.optimizer.param_groups[0]['lr'], \n                                    phase=phase,\n                                    metrics=metrics)\n            return metrics, avg_loss\n\n        elif phase == 'val' and is_last:\n            self.results_update(y_true, y_pred, phase,metrics)\n        \n        elif phase == 'test':\n            self.results_update(y_true, y_pred, phase,metrics)  \n\n    def submit(self, update_path='', is_test=False) -> None:\n        if update_path:\n            self.update_model(path=update_path)\n            self.load_model(model_phase='best_model')\n\n        if not self.is_best_model:\n            self.load_model(model_phase='best_model')\n\n        if self.device == 'cpu':\n            y_pred, img_ids = torch.IntTensor([], device=self.device), torch.IntTensor([], device=self.device)\n            \n        else:\n            y_pred, img_ids = torch.IntTensor([]).to(self.device), torch.IntTensor([]).to(self.device)\n\n        for batch_index, batch in enumerate(tqdm(self.loaders.get('submission')),1):\n            img, img_id = self.parse_batch(batch, phase='submission')\n            \n            with torch.no_grad():\n                outputs = self.model(img)\n\n            _, preds = torch.max(outputs,1)\n            y_pred = torch.cat((y_pred, preds))\n            img_ids = torch.cat((img_ids, img_id))\n\n            if is_test and batch_index == 2:\n                break\n\n        \n        y_pred_postprocessed = self.label_encoder.inverse_transform(y_pred.to('cpu').numpy())\n\n        self.submission['Id'] = img_ids.to('cpu').numpy()\n        self.submission['Predicted'] = y_pred_postprocessed\n\n        self.submission.to_csv(self.filelogs_info.get('submission_df'),header=True,index=False)\n        \n\n\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet50_epoch4_model_state_info = '../input/resnet50-epoch-4/model_state_info.pth'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet50_model_helper = NN_Model_Helper(model=resnet50_model, \n                                        optimizer=optimizer_sgd,\n                                        scheduler=exp_lr_scheduler,\n                                        loss_function=cross_entropy_loss_function,\n                                        label_encoder=le_preprocessor,\n                                        loaders=loaders,\n                                        params=params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet50_model_helper.train(model_freeze=False,\n                            update_path=resnet50_epoch4_model_state_info,\n                            epochs=1,\n                            is_test=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}